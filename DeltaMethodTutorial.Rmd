---
title: "The Delta Method in Epidemology: An Applied and Reproducible Tutorial"
author: "Miguel Angel Luque Fernandez, MA, MPH, MSc, Ph.D"
date: "10/5/2019 \n https://scholar.harvard.edu/malf/home"
output:
  html_notebook:
    code_folding: show
    highlight: default
    number_sections: no
    theme: journal
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
      toc_depth: 3
  word_document:
    toc: yes
  pdf_document:
     toc: true
     number_sections: true
  html_document:
    toc: yes
font-family: Risque
font-import: http://fonts.googleapis.com/css?family=Risque
csl: references/isme.csl
bibliography: references/bibliography.bib
---

<a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-show-count="false">Tweet</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

```{r options, echo=FALSE, eval=FALSE}
options(scipen=999, digits=5, tinytex.verbose = TRUE)
```

# Introduction

The delta method is really a theorem which states that a smooth function of an asymptotically normal estimator is also asymptotically normally distributed. It can also be viewed as a technique for approximating variance of a function of a nonlinear function of a random variable [@Armi2005]. 

In epidemiology we use routinely the delta method to compute the standard error (SE) of the risk difference (RD), the risk ratio (RR), and the odds ratio (OR) [@Agresti2010]. Often in addition to reporting parameters fitted by a model, we need to report some marginal transformation of these parameters. The transformation can generate the point estimates of our desired values, but the SE of these point estimates are not so easily calculated. 

For instance, in causal inference we compute the average treatment effect (ATE), namely $\Psi$ as a function of two random variables (i.e., the potential outcomes or counterfactuals E(Y1) and E(Y0)) [@van2006; @van2011]
$$\Psi\,=\,\text{E(Y|A=1,X)} - \text{E(Y|A=0,X)}$$
Using G-computation, these two random variables are derived from the coefficients of the parameters fitted in two different regression models [@robins1986]. Here the Functional Delta Method in addition to the Semiparametric and Empirical Process theory come to help assuming that $\Psi$ is pathwise differentiable and asymptotically linear [@kennedy2016; @kennedy2017]. Note that although the delta method is often appropriate to use with large samples, other methods can be used to estimate standard errors, such as the  bootstrap [@Efron1993; @efron1982].

Essentially, the delta method involves calculating the expansion up to the first order of a Taylor series approximation of a function [@Herberg1962]:

$$f(\hat\theta)-f(\theta)\;\approx\;f'(\theta)(\hat\theta\,-\,\theta)\,+\,\text{Op}(\frac{1}{\sqrt(n)}) \;\;(1).$$

Asymptotically  
$$\text{Op}(\frac{1}{\sqrt(n)}) \rightarrow 0 \;\text{and},$$

$$\sqrt(n)\left(f(\hat\theta)-f(\theta)\right)\; \rightarrow N(0\,, var(\theta))\;\;(2).$$ 

Therefore    
1. Asymptotically the mean of $f(\hat\theta)$ can be approximate with the empirical mean of $f(\theta)$ and  
2. The standard error (SE) of $f(\hat\theta)$ can be approximated as $f'(\theta)(var(\theta))$

For the multivariate case we first get the Taylor series approximation of the function using the first two terms of the expansion of the transformation function about the mean of of the random variable. Let $f(\cdot)$ be the transformation function and $\theta$ be the mean vector of random variables $(\text{x}\,=\,(x_1,x_2,…))$. The first two terms of the Taylor expansion are then an approximation for $\hat\theta$,

$$f(\hat\theta) \approx\, f(\theta) \nabla(\theta)^T\,(\hat\theta\,-\,\theta).$$
Where $\nabla \theta$ is the gradient of $\theta$, or a vector of partial derivatives of $\theta$. We can then take the variance of this approximation to estimate the variance of $\theta$ and thus the SE of a transformed parameter. For a random variable X with known variance Var(X), the variance of the transformation of X, $\theta$ is approximated by:

$$Var(\hat\theta)\approx  \nabla\theta^T\text{Cov}(\text{x})\nabla\theta\;\;(3).$$
where Cov(X) is the variance-covariance matrix of X [@ucla].

In summary, for observed data $\text{O}_i$, i = 1, ..., n an asymptotically linear estimator $\hat\Psi$ of an estimand $\Psi$, is an estimator that can be represented as follows: 
$$\hat\Psi\,-\,\Psi\;=\;\frac{1}{n}\sum_{i=1}^n \text{D}(\text{O}_{i})\,+\,\text{Op}(\frac{1}{\sqrt(n)})\;\;(4).$$
Where  
$$\text{D}(\text{O}_{i})=f'(\theta)(\hat\theta\,-\,\theta).$$
In other words, the difference between the estimator and estimand can be represented as the sample mean of
a fixed function (the *"Influence function”*) plus a remainder term that must converge to 0 at a rate faster than $\frac{1}{\sqrt{n}}$. The estimated influence function provides an asymptotic variance estimate for the estimator (i.e., we can apply the *Central Limit Theorem* and compute *Wald* type confidence intervals) [@van2011]. 

## Delta Method for the RD, RR, and OR (univariate case)

Using the classical 2 by 2 epidemiological table presenting outcome counts by the levels of a risk factor, we are going to derive the SE for the for the RD, RR and OR using the Delta Method

Risk      | Alive  | Dead         
--------  | ----------- | -----------
Exposed   |$\text{n}_{11}$ = ($\text{p}_{1}$) | $\text{n}_{21}$ = ($\text{p}_{2}$)   
Unexposed |$\text{n}_{12}$ = (1 -$\text{p}_{1}$)| $\text{n}_{22}$ = (1-$\text{p}_{2}$) 
  N       | $\text{N}_{1}$     |   $\text{N}_{2}$     

### Risk Difference (RD)
The risk difference is defined as follows [@Rothman2008]:  

$$\widehat{RD} \,=\, \hat \theta_{1}\,-\,\hat \theta_{2} \,=\, \hat p_{1}\,-\,\hat p_{2}.$$
Assuming that the probability of the event (**p**) can be modelled using a Bernoulli distribution with range $0\;\leq \text{p} \leq\;1$, expectation of p is E(p) = p, and the variance var(p) = p(1-p)/n.   

Given that
$$\sqrt(n)\left(f(\hat\theta)-f(\theta)\right)\; \rightarrow N(0\,, var(\theta)).$$
and using for the probability (p) the formula in (4)

$$\widehat{SE}(RD)\,=f'(\theta)(var(\theta))\;=\; \sqrt{\frac{p(1-p)}{n}}$$
We have that for the RD the SE is  
$$SE(\widehat{RD})\,=\, \sqrt{\frac{(1-\hat p_{1})}{n_{1}}}\,+\,\sqrt{\frac{(1-\hat p_{2})}{n_{2}}}\,=\,\sqrt{\frac{(1-\hat p_{1})}{n_{1}}\,+\,\frac{(1-\hat p_{2})}{n_{2}}}$$

### Risk Ratio (RR) 
$$\widehat{RR} \,=\, \frac{\hat \theta_{1}}{\hat \theta_{2}} \,=\, log\left(\frac{\hat p_{1}}{\hat p_{2}}\right)\,=\,log(\hat p_{1}) + log(\hat p_{2})$$
Given that
$$\sqrt(n)\left(f(\hat\theta)-f(\theta)\right)\; \rightarrow N(0\,, var(\theta))$$
then
$$SE(log(\hat{\theta}))\,=f'(\theta)(var(\theta))\;=\;\frac{1}{p}\sqrt{\frac{p(1-p)}{n}}\,=\,\sqrt{\frac{(1-p)}{pn}}$$
We have that
$$SE(log(\widehat{RR}))\,=\, \sqrt{\frac{(1-\hat p_{1})}{\hat p_{1}n_{1}}}\,+\,\sqrt{\frac{(1-\hat p_{2})}{\hat p_{2}n_{2}}}\,=\,\sqrt{\frac{(1-\hat p_{1})}{\hat p_{1}n_{1}}\,+\,\frac{(1-\hat p_{2})}{\hat p_{2}n_{2}}}$$

### Odds Ratio (OR) 
$$\widehat{OR} \,=\, \frac{\hat \theta_{1}}{\hat \theta_{2}} \,=\, log\left(\frac{\hat p_{1}/(1-\hat p_{1})}{\hat p_{2}/(1-\hat p_{1})}\right)\,=\,log\left(\frac{\text{n}_{11}\text{n}_{22}}{\text{n}_{12}\text{n}_{21}}\right)\,$$
Given that
$$\sqrt(n)\left(f(\hat\theta)-f(\theta)\right)\; \rightarrow N(0\,, var(\theta))$$
then
$$SE(log(\hat{\theta}))\,=f'(\theta)(var(\theta))\;=\;\frac{1}{p(1-p)}\sqrt{\frac{p(1-p)}{n}}\,=\,\sqrt{\frac{1}{n}}$$

We have that
$$SE(log(\widehat{OR}))\,=\, \sqrt{\frac{1}{n_{11}}\,+\,\frac{1}{n_{12}}\,+\,\frac{1}{n_{21}}\,+\,\frac{1}{n_{22}}}$$
Finally, using the *Central Limit Theorem* the Wald type 95\% Confidence Intervals for the RD, RR and OR can be estimated as follows:  

$$95\%\text{CI}\,=\,1.96\times\text(SE(\hat\theta))$$

# Empirical example
To illustrate the use of the Delta Method we are going to generate data based on a cancer epidemiology example where we want to estimate the effect of comorbidities (binary indicator) on one-year cancer mortality controlling for the confounding effect of age in a cohort of 1,000 patients in their middle age. We assume that it is an extremely lethal type of cancer (i.e., pancreatic cancer) thus we can expect high one-year mortality rate. Age in years was generated as a normal random variable with mean 65 years and standard deviation 5 years. Comorbidities was generated as a binary indicator and as a function of age using a binomial model. Patients$’$ one-year mortality rate was generated as a function of the patients$’$ age and the presence of comorbidities using a binomial distribution. The data generation and models specifications are provide here below: 

```{r, echo=FALSE, warning=FALSE}
# Data generation
library(tidyverse)

generateData <- function(n, seed){
set.seed(seed)
age <- rnorm(n, 65, 5)
cmbd <- rbinom(n, size=1, prob = plogis(1 - 0.05 * age))
Y <- rbinom(n, size=1, prob = plogis(1 - 0.02* age - 0.02 * cmbd))
data.frame(Y, cmbd, age)
}
```

Here we describe the data

```{r}
# Describing the data
data <- generateData(n = 1000, seed = 777) 
str(data)
summarize(
  data,
  Status = mean(Y), 
  Comorbidities = mean(cmbd),
  Age =  mean(age)
  )
```

## Delta Method for a singly univariate parameter

First, we are going to derive the SE for the single probability or risk of death (the univariate case). We compute the risk of death in our sample and its variance as follows:  

```{r}
# Risk of death
p_death = mean(data$Y)
print(p_death)
```

```{r}
# Varianze for the risk of death
 n = nrow(data)
 var_p_death = p_death * (1 - p_death) / n
 print(var_p_death)
```

Now, let be f(x) = p. Then the first derivative of f′(x) = 1. So the variance of the risk of death can be estimated using (4) as: 

$$\text{Var(P(death))}\,=\,1\times\left[\frac{\text{p(1 - p)}}{n}\right].$$
 
This can be implemented in the following R code:
```{r}
dev_p_death = 1
se_risk = sqrt((dev_p_death) * var_p_death)
print(se_risk)
```

To check that our results are consistent with the implementation of the Delta Method function provide by the **sms** R package used for advanced Geographical Analysis [@kavroudakis2015].

```{r}
# install.packages("msm")
library(msm)
se_risk_delta = deltamethod(g = ~ x1, 
                            mean = p_death,         
                            cov  = var_p_death)
print(se_risk_delta)

cat("Are the same se_risk and se_risk_delta?")

ifelse(
  se_risk == se_risk_delta,
  print("Yes")
)
```

## Conditional Odds Ratio (COR): Multivariable Case

Let$'$s now compute the SE for the COR derived from a multivariable logistic regression model. Note that the COR transformation is a function of the regression coefficients from the logistic model. First we estimate the conditional probability of the risk of death for those patients with comorbidities adjusting for age. The model summary is described here below. The probability of death for a cancer patient in our sample with comorbidities compared with a patient without comorbidities and in average with the same age is approximately 40\% higher: 

```{r}
m1 <- glm(Y ~ age + cmbd, data = data, family = binomial)
summary(m1)
b1 <- coef(m1)[3]
cat("One-year mortality risk for patients with comorbidities vs no comorbidities is:") 
exp(b1)
```

We now, can derive the SE for the conditional OR using the formula (4) for the multivariate case. Note that the first derivative for the exponential function is equal to exponential and that to get the covariance of the parameter fitted in the model we use the command "vcov" in R.

```{r}
grad <- exp(b1)
vcov(m1)
vb1 <- vcov(m1)[3,3]
se <- grad %*% vb1 %*% grad
se_cor <- sqrt(se); se_cor
```

Now, we have to check that our results are consistent with the implementation of the Delta Method function provide by the **sms** R package  [@kavroudakis2015]
```{r}
se_cor_delta <- deltamethod(~ exp(x1), b1, vb1); se_cor_delta

cat("Are the same se_cor and se_cor_delta?")

ifelse(
  se_cor == se_cor_delta,
  print("Yes"),print("No")
)
```

## Conditional Risk Ratio (CRR): multivariable case

Let$'$s now compute the SE for the conditional multivariable RR derived from the predicted probabilities of a  multivariable logistic regression model. First we fit the model with the binary indicator of one-year mortality as dependent variable and patients$’$ age and comorbidities as independent variables. Then, from the fitted model and using the **predict** function we derive the probability of death from cancer patients aged 75 years and with comorbidities versus the probability of death for cancer patients aged 45 years old and without comorbidities, respectively. Finally, we compute the conditional RR (CRR) as the ratio between both probabilities. As we can see the risk of death in a population where cancer patients were aged 75 years with  comorbidities is approximately 29\% higher than the risk of one-year mortality in population of cancer patients all of them aged 45 years and without comorbidities:

```{r}
m2 <- glm(Y ~ age + cmbd, data = data, family = binomial)
p75 <- predict(m2, newdata = data.frame(age = 75, cmbd = 1), type="response")
p45 <- predict(m2, newdata = data.frame(age = 45, cmbd = 0), type="response")
mrr <- p45 / p75;
cat("Marginal Risk Ratio: ", mrr)
```

Let$'$s now to compute the SE for the CRR. Note that the relative risk transformation is a function of the regression coefficients. First, we should define the conditional probability in terms of the regression coefficients. In our model, given patients age and comorbidities, the probability of one-year mortality is:
$$\text{P(Y=1|X)}\,=\,\frac{1}{1\,+\,\text{exp}(−\sum_{i=1}^k \beta(X))}$$
Where k is the number of parameters in the model $\beta\,=\,(\beta_{0},\beta_{1},\beta_{2})$. Therefore,
the probabality of one-year mortality for cancer patients aged 45 years without comorbidities is 
$$\text{P(1)(Y = 1|X1 = 45, X2 = 0)}\,=\,\frac{1}{1\,+\,exp(−\beta_{0}\,-\,\beta_{1}\times 45\,-\,\beta_{2}\times0)},$$
and the probabality of one-year mortality for cancer patients aged 75 years with comorbidities is 
$$\text{P(2)(Y = 1|X1 = 75, X2 = 1)}\,=\,\frac{1}{1\,+\,exp(−\beta_{0}\,-\,\beta_{1}\times 75\,-\,\beta_{2}\times1)}.$$
Note that the MRR is a function of the regression coefficients from the logistic model. Thus, now we use the equation in (3) to get: 
$$\text{f(x)}\,=\,\frac{\frac{1}{1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4)}}{\frac{1}{1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x1\,-\,\beta_{2}x3)}},$$
which simplifies to:
$$\text{f(x)}\,=\,\frac{1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4)}{1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x1\,-\,\beta_{2}x3)}.$$
We now need to solve a more complicate derivative (a partial derivative) for $f'$ but one can use the online open source available software "Wolfram alpha: https://www.wolframalpha.com/" to readily get the results for $f'$ and then apply the formula (3). Using the product and chain rules, we obtain the following partial derivatives:
$$\frac{df}{d\beta_{0}}\,=\,\text{−exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4))\times \text{p}\,+\,(1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4))\times \text{p}(1\,–\,\text{p}),$$
then,
$$\frac{df}{d\beta_{1}}\,=\,\text{−exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4))\times x2 \times \text{p}\,+\,(1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4))\times x1 \times \text{p}(1\,–\,\text{p}),$$
and, 
$$\frac{df}{d\beta_{2}}\,=\,\text{−exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4))\times x4 \times \text{p}\,+\,(1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x3\,-\,\beta_{2} x4))\times x3 \times \text{p}(1\,–\,\text{p})$$
where p is 
$$\text{P(Y=1|X1,X2)}\,=\,\frac{1}{1\,+\text{exp}(−\beta_{0}\,-\,\beta_{1}x1\,-\,\beta_{2}x3)},$$
i.e., the probability of one-year mortality for cancer patients aged 45 years without comorbidities. 

Let’s calculate our partial derivative in R as follows:
```{r}
x1 <- 45
x2 <- 75
x3 <- 0
x4 <- 1
b0 <- coef(m2)[1]
b1 <- coef(m2)[2]
b2 <- coef(m2)[3]
e1 <- exp(-b0 - 45*b1 - 0*b2)
e2 <- exp(-b0 - 75*b1 - 1*b2)
p1 <- 1 / (1 + e1)
p2 <- 1 / (1 + e2)
dfdb0 <- -e2*p1 + (1 + e2)*p1*(1 - p1)
dfdb1 <- -x2*e2*p1 + (1 + e2)*x1*p1*(1 - p1)
dfdb2 <- -x4*e2*p1 + (1 + e2)*x3*p1*(1 - p1)
grad <- c(dfdb0, dfdb1, dfdb2)
vG <- t(grad) %*% vcov(m2) %*% (grad)
se_mrr <- c(sqrt(vG));se_mrr
```

Now, let$'$s again to check if our results are consistent with the implementation of the Delta Method function provide by the **sms** R package [@kavroudakis2015]. We obtain the same results for the SE of the mrr computed before (0.31377)

```{r}
se_mrr_delta <- deltamethod( ~(1 + exp(-x1 -75*x2 -1*x3)) / (1 + exp(-x1 -45*x2 -0*x4)), 
             c(b0, b1, b2), 
             vcov(m2)
             ); se_mrr_delta
```
Finally, let$'$s compute the 95\% confidence intervals (CI):
```{r}
lb <- mrr - 1.96*sqrt(vG)
ub <- mrr + 1.96*sqrt(vG)
cat("\n Conditional Risk Rartio (95%CI): ") ; cat(mrr, "(", lb,",", ub,")")
```

# Session Info 
```{r session-info}
devtools::session_info()
```

# Thank you  
Thank you for participating in this tutorial.  
If you have updates or changes that you would like to make, please send <a href="https://github.com/migariane/DeltaMethodTutorial" target="_blank">me</a> a pull request.
Alternatively, if you have any questions, please e-mail me. 
You can cite this repository as:        
Luque-Fernandez MA, (2019). Delta Method Toturial: An Applied and Reproducible Tutorial. GitHub repository, https://github.com/migariane/DeltaMethodTutorial.    
**Miguel Angel Luque Fernandez**     
**E-mail:** *miguel-angel.luque at lshtm.ac.uk*  
**Twitter** `@WATZILEI`  

# References 
